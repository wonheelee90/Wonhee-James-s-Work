{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read in required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read in data\n",
    "train = pd.read_csv('train_sample.csv')\n",
    "test = pd.read_csv('test_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>x11</th>\n",
       "      <th>x12</th>\n",
       "      <th>x13</th>\n",
       "      <th>x14</th>\n",
       "      <th>x15</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2.639057</td>\n",
       "      <td>2.639057</td>\n",
       "      <td>2.639057</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.660575</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.477300</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.090910</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.596100</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.318120</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.141900</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3.044522</td>\n",
       "      <td>3.044522</td>\n",
       "      <td>3.044522</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.364751</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.073500</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5.129899</td>\n",
       "      <td>3.367296</td>\n",
       "      <td>4.442651</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>3.367296</td>\n",
       "      <td>8.407602</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.327267</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        x1        x2        x3        x4        x5        x6  \\\n",
       "0           0  2.639057  2.639057  2.639057  0.693147  0.000000  6.660575   \n",
       "1           1  2.197225  2.197225  2.197225  0.693147  0.000000  7.090910   \n",
       "2           2  2.079442  2.079442  2.079442  0.693147  0.000000  5.318120   \n",
       "3           3  3.044522  3.044522  3.044522  0.693147  0.000000  6.364751   \n",
       "4           4  5.129899  3.367296  4.442651  0.693147  3.367296  8.407602   \n",
       "\n",
       "    x7        x8         x9  x10  x11  x12  x13  x14  x15  y  \n",
       "0  1.0  0.477300  45.000000    1    1    1    1    0    0  0  \n",
       "1  1.0  0.596100  43.000000    1    0    0    0    0    0  0  \n",
       "2  1.0  0.141900  50.000000    1    0    1    1    0    0  0  \n",
       "3  1.0  0.073500  27.000000    1    0    1    1    0    0  0  \n",
       "4  4.0  0.327267  33.333333    1    1    1    1    0    1  0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## The training set is composed of 15 predictors(9 quantitative and 6 flags) and 1 response variable. \n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>x11</th>\n",
       "      <th>x12</th>\n",
       "      <th>x13</th>\n",
       "      <th>x14</th>\n",
       "      <th>x15</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.397895</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.673323</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.097200</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.833213</td>\n",
       "      <td>2.833213</td>\n",
       "      <td>2.833213</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.175867</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.098300</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.178054</td>\n",
       "      <td>3.178054</td>\n",
       "      <td>3.178054</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.432940</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.127600</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.263330</td>\n",
       "      <td>6.836259</td>\n",
       "      <td>7.218910</td>\n",
       "      <td>2.890372</td>\n",
       "      <td>5.921578</td>\n",
       "      <td>10.627697</td>\n",
       "      <td>1.266667</td>\n",
       "      <td>0.261334</td>\n",
       "      <td>155.855556</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.543295</td>\n",
       "      <td>3.465736</td>\n",
       "      <td>4.543295</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.260082</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.110300</td>\n",
       "      <td>13.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x1        x2        x3        x4        x5         x6        x7  \\\n",
       "0  2.397895  2.397895  2.397895  0.693147  0.000000   5.673323  1.000000   \n",
       "1  2.833213  2.833213  2.833213  0.693147  0.000000   6.175867  1.000000   \n",
       "2  3.178054  3.178054  3.178054  0.693147  0.000000   6.432940  1.000000   \n",
       "3  7.263330  6.836259  7.218910  2.890372  5.921578  10.627697  1.266667   \n",
       "4  4.543295  3.465736  4.543295  0.693147  0.000000   9.260082  1.000000   \n",
       "\n",
       "         x8          x9  x10  x11  x12  x13  x14  x15  y  \n",
       "0  0.097200   40.000000    1    0    1    1    0    0  0  \n",
       "1  0.098300   25.000000    1    0    0    1    0    0  0  \n",
       "2  0.127600   35.000000    1    0    1    1    0    0  0  \n",
       "3  0.261334  155.855556    1    0    0    1    0    0  0  \n",
       "4  0.110300   13.666667    1    0    0    1    0    0  0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## The test set is of the same structure. The training and test sets are non-overlapping.\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    875000\n",
       "1      1501\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Note that there is a severe imbalance between positive & negative lables (response variable)\n",
    "train['y'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    933000\n",
       "1      1332\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Note that there is a severe imbalance between positive & negative lables (response variable)\n",
    "test['y'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## In order to alleviate the effects of this imbalance, let's try downsampling the majority class to create a 50/50 training set\n",
    "labels = train.y\n",
    "\n",
    "# Indicies of each class' observations\n",
    "i_class0 = np.where(labels == 0)[0]\n",
    "i_class1 = np.where(labels == 1)[0]\n",
    "\n",
    "# Number of observations in each class\n",
    "n_class0 = len(i_class0)\n",
    "n_class1 = len(i_class1)\n",
    "\n",
    "# For every observation of class 1, randomly sample from class 0 without replacement\n",
    "np.random.seed(0)\n",
    "i_class0_downsampled = np.random.choice(i_class0, size=n_class1, replace=False)\n",
    "\n",
    "# Join together class 1's target vector with the downsampled class 0's target vector\n",
    "newdata = train.iloc[i_class0_downsampled].append(train.iloc[i_class1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3002, 17)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Our resulting downsampled training set consists of 3002 entries, 50% positive and 50% negative\n",
    "np.shape(newdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>x11</th>\n",
       "      <th>x12</th>\n",
       "      <th>x13</th>\n",
       "      <th>x14</th>\n",
       "      <th>x15</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56481</th>\n",
       "      <td>56481</td>\n",
       "      <td>2.772589</td>\n",
       "      <td>2.772589</td>\n",
       "      <td>2.772589</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.077642</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.071800</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772495</th>\n",
       "      <td>772495</td>\n",
       "      <td>3.332205</td>\n",
       "      <td>3.332205</td>\n",
       "      <td>3.332205</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.664409</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.145900</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521739</th>\n",
       "      <td>521739</td>\n",
       "      <td>4.543295</td>\n",
       "      <td>4.143135</td>\n",
       "      <td>3.465736</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.493186</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.384650</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366330</th>\n",
       "      <td>366330</td>\n",
       "      <td>6.767343</td>\n",
       "      <td>6.380123</td>\n",
       "      <td>6.767343</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>3.465736</td>\n",
       "      <td>10.076516</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.134003</td>\n",
       "      <td>11.486842</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59868</th>\n",
       "      <td>59868</td>\n",
       "      <td>5.231109</td>\n",
       "      <td>4.143135</td>\n",
       "      <td>5.231109</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.703145</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.756360</td>\n",
       "      <td>34.900000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0        x1        x2        x3        x4        x5  \\\n",
       "56481        56481  2.772589  2.772589  2.772589  0.693147  0.000000   \n",
       "772495      772495  3.332205  3.332205  3.332205  0.693147  0.000000   \n",
       "521739      521739  4.543295  4.143135  3.465736  0.693147  0.000000   \n",
       "366330      366330  6.767343  6.380123  6.767343  2.564949  3.465736   \n",
       "59868        59868  5.231109  4.143135  5.231109  1.098612  0.000000   \n",
       "\n",
       "               x6   x7        x8         x9  x10  x11  x12  x13  x14  x15  y  \n",
       "56481    6.077642  1.0  0.071800  25.000000    1    0    0    0    0    0  0  \n",
       "772495   6.664409  1.0  0.145900  46.000000    1    0    0    1    0    0  0  \n",
       "521739   9.493186  1.5  0.384650  64.000000    1    1    0    1    0    0  0  \n",
       "366330  10.076516  1.0  0.134003  11.486842    1    0    0    1    0    1  0  \n",
       "59868    9.703145  1.0  0.756360  34.900000    1    1    1    1    0    0  0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    False\n",
       "x1            False\n",
       "x2            False\n",
       "x3            False\n",
       "x4            False\n",
       "x5            False\n",
       "x6            False\n",
       "x7            False\n",
       "x8            False\n",
       "x9            False\n",
       "x10           False\n",
       "x11           False\n",
       "x12           False\n",
       "x13           False\n",
       "x14           False\n",
       "x15           False\n",
       "y             False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check for any 'na' values\n",
    "newdata.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now we are ready to begin modeling. Let's divide the training data into features and response\n",
    "X = newdata.drop('y', axis = 1)\n",
    "y = newdata.loc[:, 'y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>x11</th>\n",
       "      <th>x12</th>\n",
       "      <th>x13</th>\n",
       "      <th>x14</th>\n",
       "      <th>x15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56481</th>\n",
       "      <td>56481</td>\n",
       "      <td>2.772589</td>\n",
       "      <td>2.772589</td>\n",
       "      <td>2.772589</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.077642</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.071800</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772495</th>\n",
       "      <td>772495</td>\n",
       "      <td>3.332205</td>\n",
       "      <td>3.332205</td>\n",
       "      <td>3.332205</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.664409</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.145900</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521739</th>\n",
       "      <td>521739</td>\n",
       "      <td>4.543295</td>\n",
       "      <td>4.143135</td>\n",
       "      <td>3.465736</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.493186</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.384650</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366330</th>\n",
       "      <td>366330</td>\n",
       "      <td>6.767343</td>\n",
       "      <td>6.380123</td>\n",
       "      <td>6.767343</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>3.465736</td>\n",
       "      <td>10.076516</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.134003</td>\n",
       "      <td>11.486842</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59868</th>\n",
       "      <td>59868</td>\n",
       "      <td>5.231109</td>\n",
       "      <td>4.143135</td>\n",
       "      <td>5.231109</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.703145</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.756360</td>\n",
       "      <td>34.900000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0        x1        x2        x3        x4        x5  \\\n",
       "56481        56481  2.772589  2.772589  2.772589  0.693147  0.000000   \n",
       "772495      772495  3.332205  3.332205  3.332205  0.693147  0.000000   \n",
       "521739      521739  4.543295  4.143135  3.465736  0.693147  0.000000   \n",
       "366330      366330  6.767343  6.380123  6.767343  2.564949  3.465736   \n",
       "59868        59868  5.231109  4.143135  5.231109  1.098612  0.000000   \n",
       "\n",
       "               x6   x7        x8         x9  x10  x11  x12  x13  x14  x15  \n",
       "56481    6.077642  1.0  0.071800  25.000000    1    0    0    0    0    0  \n",
       "772495   6.664409  1.0  0.145900  46.000000    1    0    0    1    0    0  \n",
       "521739   9.493186  1.5  0.384650  64.000000    1    1    0    1    0    0  \n",
       "366330  10.076516  1.0  0.134003  11.486842    1    0    0    1    0    1  \n",
       "59868    9.703145  1.0  0.756360  34.900000    1    1    1    1    0    0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's further divide our training set into a training/validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's also split our test set into features/response\n",
    "X_test = test.drop('y', axis = 1)\n",
    "y_test = test.loc[:, 'y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       1.00      1.00      1.00       488\n",
      "    Positive       1.00      1.00      1.00       413\n",
      "\n",
      "    accuracy                           1.00       901\n",
      "   macro avg       1.00      1.00      1.00       901\n",
      "weighted avg       1.00      1.00      1.00       901\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Now we are ready to train our xgboost classifier. First, lets use the validation set to observe performance\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train , y_train)\n",
    "y_val_pred = model.predict(X_val)\n",
    "target_names = ['Negative', 'Positive']\n",
    "print(metrics.classification_report(y_val, y_val_pred,target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[488   0]\n",
      " [  0 413]]\n"
     ]
    }
   ],
   "source": [
    "## Here's what the results of our validation set look like\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_val_pred, y_val)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "feature_names mismatch: ['Unnamed: 0', 'x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'x10', 'x11', 'x12', 'x13', 'x14', 'x15'] ['x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'x10', 'x11', 'x12', 'x13', 'x14', 'x15']\nexpected Unnamed: 0 in input data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-1aeafe35269b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## Here's what the results of our test set look like\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my_test_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mconfusion_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, output_margin, ntree_limit, validate_features)\u001b[0m\n\u001b[1;32m    789\u001b[0m                                                  \u001b[0moutput_margin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_margin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m                                                  \u001b[0mntree_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mntree_limit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m                                                  validate_features=validate_features)\n\u001b[0m\u001b[1;32m    792\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput_margin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m             \u001b[0;31m# If output_margin is active, simply return the scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, output_margin, ntree_limit, pred_leaf, pred_contribs, approx_contribs, pred_interactions, validate_features)\u001b[0m\n\u001b[1;32m   1282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1283\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidate_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1284\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1286\u001b[0m         \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_bst_ulong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_validate_features\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1689\u001b[0m                 raise ValueError(msg.format(self.feature_names,\n\u001b[0;32m-> 1690\u001b[0;31m                                             data.feature_names))\n\u001b[0m\u001b[1;32m   1691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1692\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_split_value_histogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_pandas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: feature_names mismatch: ['Unnamed: 0', 'x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'x10', 'x11', 'x12', 'x13', 'x14', 'x15'] ['x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'x10', 'x11', 'x12', 'x13', 'x14', 'x15']\nexpected Unnamed: 0 in input data"
     ]
    }
   ],
   "source": [
    "## Here's what the results of our test set look like\n",
    "y_test_pred = model.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test_pred, y_test)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Can we do even better by playing with the parameters?\n",
    "## To do this, let's create a parameter grid that can test out combinations of multiple parameters\n",
    "param_grid = {\n",
    "    'max_depth': [2, 5],\n",
    "    'learning_rate': [0.005, 0.01],\n",
    "    'booster' : ['gbtree'],\n",
    "    'n_estimators': [500, 1000],\n",
    "    'subsample' : [1],\n",
    "    'colsample_bytree': [0.5, 1],\n",
    "    'colsample_bylevel': [0.5, 1],\n",
    "    'colsample_bynode': [0.5, 1]\n",
    "}\n",
    "# Create a based model\n",
    "xgb = XGBClassifier(random_state=0)\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = xgb, param_grid = param_grid, \n",
    "                          cv = 5, n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fit the grid search to the training data\n",
    "grid_result = grid_search.fit(X_train, y_train)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's see what our best model parameters are\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "#for mean, stdev, param in zip(means, stds, params):\n",
    " #   print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using the best model identified by the grid search, lets re-run the model on the validation set\n",
    "best_grid = grid_search.best_estimator_\n",
    "model = best_grid\n",
    "model.fit(X_train , y_train)\n",
    "y_val_pred = model.predict(X_val)\n",
    "target_names = ['Negative', 'Positive']\n",
    "print(metrics.classification_report(y_val, y_val_pred,target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here's what the results of our validation set look like\n",
    "## Results are very similar to our \"default\" classifier tested prior\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_val_pred, y_val)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using the best model identified by the grid search, lets re-run the model on the test set\n",
    "model.fit(X_train , y_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "target_names = ['Negative', 'Positive']\n",
    "print(metrics.classification_report(y_test, y_test_pred,target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here's what the results of our test set look like\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test_pred, y_test)\n",
    "print(confusion_matrix)\n",
    "## We can see below that this best-fit model captures a bit more True Positives at the exepnse of a bit more False Positives\n",
    "## Given the imbalance and the relatively higher value of TPs(compared to the penalty of a FP), we will accept this exchange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Let's take a look at feature importances. Can we remove some features to get a better model?\n",
    "feature_importances = pd.Series(model.feature_importances_, X_train.columns).sort_values(ascending = False)\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Quick plot of features and their importances\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "sns.barplot(y=feature_importances.index, x=feature_importances.values)\n",
    "plt.title('Feature Importances')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Based on the above, let's try setting the cutoff threshold at 0.04 and remove the rest\n",
    "threshold = 0.04\n",
    "imp_feats = list(feature_importances[feature_importances>threshold].keys())\n",
    "imp_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Only pick features that have an importance of more than the threshold 0.04\n",
    "sfm = SelectFromModel(model, threshold)\n",
    "\n",
    "# Train the selector\n",
    "sfm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the data to create a new dataset containing only the most important features\n",
    "# Note: We have to apply the transform to both the training X and test X data.\n",
    "X_important_train = sfm.transform(X_train)\n",
    "X_important_test = sfm.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new random forest classifier for the most important features\n",
    "model_important = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bynode=1, colsample_bytree=0.5, gamma=0,\n",
    "       learning_rate=0.01, max_delta_step=0, max_depth=5,\n",
    "       min_child_weight=1, missing=None, n_estimators=500, n_jobs=1,\n",
    "       nthread=None, objective='binary:logistic', random_state=0,\n",
    "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "       silent=True, subsample=1)\n",
    "\n",
    "# Train the new classifier on the new dataset containing the most important features\n",
    "model_important.fit(X_important_train, y_train)\n",
    "y_pred = model_important.predict(X_important_test)\n",
    "target_names = ['Negative', 'Positive']\n",
    "print(metrics.classification_report(y_test, y_pred,target_names=target_names))\n",
    "\n",
    "# There doesn't appear to be much of a difference compared to our previous model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's look at the confusion matrix for the test set\n",
    "y_pred = model_important.predict(X_important_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_pred, y_test)\n",
    "print(confusion_matrix)\n",
    "\n",
    "## We'll just use the original best_grid model to look at raw predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's see what our raw predictions look like with our original best grid model\n",
    "raw_preds = model.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## % of predictions over 0.5\n",
    "len([pred for pred in raw_preds if pred>=0.5])/float(len(raw_preds))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Here is what the distribution of raw predictions look like: long tail, skewed right as expected\n",
    "%matplotlib inline\n",
    "plt.hist(raw_preds, bins = 10, range = (0,1))[0]/len(raw_preds)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's do some data manipulation to see what the histogram above looks like just for positive labels\n",
    "X_test['raw_preds'] = raw_preds\n",
    "X_test['y'] = y_test\n",
    "X_test[['raw_preds', 'y']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Below is a histogram of positive labels in the test set and their corresponding scores\n",
    "positives = X_test[X_test['y']>0]\n",
    "plt.hist(positives.raw_preds)\n",
    "## 61% of the positives received scores of 0.9 or higher (817/1332, 61.3%)\n",
    "## 73% of the positives received scores of 0.8 or higher (972/1332, 73.0%)\n",
    "## 86% of the positives received scores of 0.5 or higher (1145/1332, 86.0%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's save our xgboost model using the pickle module\n",
    "import pickle\n",
    "pickle.dump(model, open(\"xgb.pickle.dat\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We can use load the model with the following for future use\n",
    "loaded_model = pickle.load(open(\"xgb.pickle.dat\", \"rb\"))\n",
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
