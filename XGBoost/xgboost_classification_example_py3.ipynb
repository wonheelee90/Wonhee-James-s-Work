{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read in required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read in data\n",
    "train = pd.read_csv('train_sample.csv')\n",
    "test = pd.read_csv('test_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>x11</th>\n",
       "      <th>x12</th>\n",
       "      <th>x13</th>\n",
       "      <th>x14</th>\n",
       "      <th>x15</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.639057</td>\n",
       "      <td>2.639057</td>\n",
       "      <td>2.639057</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.660575</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.477300</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.197225</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.090910</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.596100</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.079442</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.318120</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.141900</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.044522</td>\n",
       "      <td>3.044522</td>\n",
       "      <td>3.044522</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.364751</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.073500</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.129899</td>\n",
       "      <td>3.367296</td>\n",
       "      <td>4.442651</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>3.367296</td>\n",
       "      <td>8.407602</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.327267</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x1        x2        x3        x4        x5        x6   x7        x8  \\\n",
       "0  2.639057  2.639057  2.639057  0.693147  0.000000  6.660575  1.0  0.477300   \n",
       "1  2.197225  2.197225  2.197225  0.693147  0.000000  7.090910  1.0  0.596100   \n",
       "2  2.079442  2.079442  2.079442  0.693147  0.000000  5.318120  1.0  0.141900   \n",
       "3  3.044522  3.044522  3.044522  0.693147  0.000000  6.364751  1.0  0.073500   \n",
       "4  5.129899  3.367296  4.442651  0.693147  3.367296  8.407602  4.0  0.327267   \n",
       "\n",
       "          x9  x10  x11  x12  x13  x14  x15  y  \n",
       "0  45.000000    1    1    1    1    0    0  0  \n",
       "1  43.000000    1    0    0    0    0    0  0  \n",
       "2  50.000000    1    0    1    1    0    0  0  \n",
       "3  27.000000    1    0    1    1    0    0  0  \n",
       "4  33.333333    1    1    1    1    0    1  0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## The training set is composed of 15 predictors(9 quantitative and 6 flags) and 1 response variable. \n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>x11</th>\n",
       "      <th>x12</th>\n",
       "      <th>x13</th>\n",
       "      <th>x14</th>\n",
       "      <th>x15</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.397895</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.673323</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.097200</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.833213</td>\n",
       "      <td>2.833213</td>\n",
       "      <td>2.833213</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.175867</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.098300</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.178054</td>\n",
       "      <td>3.178054</td>\n",
       "      <td>3.178054</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.432940</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.127600</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.263330</td>\n",
       "      <td>6.836259</td>\n",
       "      <td>7.218910</td>\n",
       "      <td>2.890372</td>\n",
       "      <td>5.921578</td>\n",
       "      <td>10.627697</td>\n",
       "      <td>1.266667</td>\n",
       "      <td>0.261334</td>\n",
       "      <td>155.855556</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.543295</td>\n",
       "      <td>3.465736</td>\n",
       "      <td>4.543295</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.260082</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.110300</td>\n",
       "      <td>13.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x1        x2        x3        x4        x5         x6        x7  \\\n",
       "0  2.397895  2.397895  2.397895  0.693147  0.000000   5.673323  1.000000   \n",
       "1  2.833213  2.833213  2.833213  0.693147  0.000000   6.175867  1.000000   \n",
       "2  3.178054  3.178054  3.178054  0.693147  0.000000   6.432940  1.000000   \n",
       "3  7.263330  6.836259  7.218910  2.890372  5.921578  10.627697  1.266667   \n",
       "4  4.543295  3.465736  4.543295  0.693147  0.000000   9.260082  1.000000   \n",
       "\n",
       "         x8          x9  x10  x11  x12  x13  x14  x15  y  \n",
       "0  0.097200   40.000000    1    0    1    1    0    0  0  \n",
       "1  0.098300   25.000000    1    0    0    1    0    0  0  \n",
       "2  0.127600   35.000000    1    0    1    1    0    0  0  \n",
       "3  0.261334  155.855556    1    0    0    1    0    0  0  \n",
       "4  0.110300   13.666667    1    0    0    1    0    0  0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## The test set is of the same structure. The training and test sets are non-overlapping.\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    875000\n",
       "1      1501\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Note that there is a severe imbalance between positive & negative lables (response variable)\n",
    "train['y'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    933000\n",
       "1      1332\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Note that there is a severe imbalance between positive & negative lables (response variable)\n",
    "test['y'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## In order to alleviate the effects of this imbalance, let's try downsampling the majority class to create a 50/50 training set\n",
    "labels = train.y\n",
    "\n",
    "# Indicies of each class' observations\n",
    "i_class0 = np.where(labels == 0)[0]\n",
    "i_class1 = np.where(labels == 1)[0]\n",
    "\n",
    "# Number of observations in each class\n",
    "n_class0 = len(i_class0)\n",
    "n_class1 = len(i_class1)\n",
    "\n",
    "# For every observation of class 1, randomly sample from class 0 without replacement\n",
    "np.random.seed(0)\n",
    "i_class0_downsampled = np.random.choice(i_class0, size=n_class1, replace=False)\n",
    "\n",
    "# Join together class 1's target vector with the downsampled class 0's target vector\n",
    "newdata = train.iloc[i_class0_downsampled].append(train.iloc[i_class1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3002, 16)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Our resulting downsampled training set consists of 3002 entries, 50% positive and 50% negative\n",
    "np.shape(newdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>x11</th>\n",
       "      <th>x12</th>\n",
       "      <th>x13</th>\n",
       "      <th>x14</th>\n",
       "      <th>x15</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56481</th>\n",
       "      <td>2.772589</td>\n",
       "      <td>2.772589</td>\n",
       "      <td>2.772589</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.077642</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.071800</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772495</th>\n",
       "      <td>3.332205</td>\n",
       "      <td>3.332205</td>\n",
       "      <td>3.332205</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.664409</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.145900</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521739</th>\n",
       "      <td>4.543295</td>\n",
       "      <td>4.143135</td>\n",
       "      <td>3.465736</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.493186</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.384650</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366330</th>\n",
       "      <td>6.767343</td>\n",
       "      <td>6.380123</td>\n",
       "      <td>6.767343</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>3.465736</td>\n",
       "      <td>10.076516</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.134003</td>\n",
       "      <td>11.486842</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59868</th>\n",
       "      <td>5.231109</td>\n",
       "      <td>4.143135</td>\n",
       "      <td>5.231109</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.703145</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.756360</td>\n",
       "      <td>34.900000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              x1        x2        x3        x4        x5         x6   x7  \\\n",
       "56481   2.772589  2.772589  2.772589  0.693147  0.000000   6.077642  1.0   \n",
       "772495  3.332205  3.332205  3.332205  0.693147  0.000000   6.664409  1.0   \n",
       "521739  4.543295  4.143135  3.465736  0.693147  0.000000   9.493186  1.5   \n",
       "366330  6.767343  6.380123  6.767343  2.564949  3.465736  10.076516  1.0   \n",
       "59868   5.231109  4.143135  5.231109  1.098612  0.000000   9.703145  1.0   \n",
       "\n",
       "              x8         x9  x10  x11  x12  x13  x14  x15  y  \n",
       "56481   0.071800  25.000000    1    0    0    0    0    0  0  \n",
       "772495  0.145900  46.000000    1    0    0    1    0    0  0  \n",
       "521739  0.384650  64.000000    1    1    0    1    0    0  0  \n",
       "366330  0.134003  11.486842    1    0    0    1    0    1  0  \n",
       "59868   0.756360  34.900000    1    1    1    1    0    0  0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x1     False\n",
       "x2     False\n",
       "x3     False\n",
       "x4     False\n",
       "x5     False\n",
       "x6     False\n",
       "x7     False\n",
       "x8     False\n",
       "x9     False\n",
       "x10    False\n",
       "x11    False\n",
       "x12    False\n",
       "x13    False\n",
       "x14    False\n",
       "x15    False\n",
       "y      False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check for any 'na' values\n",
    "newdata.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now we are ready to begin modeling. Let's divide the training data into features and response\n",
    "X = newdata.drop('y', axis = 1)\n",
    "y = newdata.loc[:, 'y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>x11</th>\n",
       "      <th>x12</th>\n",
       "      <th>x13</th>\n",
       "      <th>x14</th>\n",
       "      <th>x15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56481</th>\n",
       "      <td>2.772589</td>\n",
       "      <td>2.772589</td>\n",
       "      <td>2.772589</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.077642</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.071800</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772495</th>\n",
       "      <td>3.332205</td>\n",
       "      <td>3.332205</td>\n",
       "      <td>3.332205</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.664409</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.145900</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521739</th>\n",
       "      <td>4.543295</td>\n",
       "      <td>4.143135</td>\n",
       "      <td>3.465736</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.493186</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.384650</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366330</th>\n",
       "      <td>6.767343</td>\n",
       "      <td>6.380123</td>\n",
       "      <td>6.767343</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>3.465736</td>\n",
       "      <td>10.076516</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.134003</td>\n",
       "      <td>11.486842</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59868</th>\n",
       "      <td>5.231109</td>\n",
       "      <td>4.143135</td>\n",
       "      <td>5.231109</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.703145</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.756360</td>\n",
       "      <td>34.900000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              x1        x2        x3        x4        x5         x6   x7  \\\n",
       "56481   2.772589  2.772589  2.772589  0.693147  0.000000   6.077642  1.0   \n",
       "772495  3.332205  3.332205  3.332205  0.693147  0.000000   6.664409  1.0   \n",
       "521739  4.543295  4.143135  3.465736  0.693147  0.000000   9.493186  1.5   \n",
       "366330  6.767343  6.380123  6.767343  2.564949  3.465736  10.076516  1.0   \n",
       "59868   5.231109  4.143135  5.231109  1.098612  0.000000   9.703145  1.0   \n",
       "\n",
       "              x8         x9  x10  x11  x12  x13  x14  x15  \n",
       "56481   0.071800  25.000000    1    0    0    0    0    0  \n",
       "772495  0.145900  46.000000    1    0    0    1    0    0  \n",
       "521739  0.384650  64.000000    1    1    0    1    0    0  \n",
       "366330  0.134003  11.486842    1    0    0    1    0    1  \n",
       "59868   0.756360  34.900000    1    1    1    1    0    0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's further divide our training set into a training/validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's also split our test set into features/response\n",
    "X_test = test.drop('y', axis = 1)\n",
    "y_test = test.loc[:, 'y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.89      0.90      0.90       488\n",
      "    Positive       0.88      0.87      0.88       413\n",
      "\n",
      "    accuracy                           0.89       901\n",
      "   macro avg       0.89      0.89      0.89       901\n",
      "weighted avg       0.89      0.89      0.89       901\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Now we are ready to train our xgboost classifier. First, lets use the validation set to observe performance\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train , y_train)\n",
    "y_val_pred = model.predict(X_val)\n",
    "target_names = ['Negative', 'Positive']\n",
    "print(metrics.classification_report(y_val, y_val_pred,target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[440  54]\n",
      " [ 48 359]]\n"
     ]
    }
   ],
   "source": [
    "## Here's what the results of our validation set look like\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_val_pred, y_val)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[842782    183]\n",
      " [ 90218   1149]]\n"
     ]
    }
   ],
   "source": [
    "## Here's what the results of our test set look like\n",
    "y_test_pred = model.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test_pred, y_test)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Can we do even better by playing with the parameters?\n",
    "## To do this, let's create a parameter grid that can test out combinations of multiple parameters\n",
    "param_grid = {\n",
    "    'max_depth': [2, 5],\n",
    "    'learning_rate': [0.005, 0.01],\n",
    "    'booster' : ['gbtree'],\n",
    "    'n_estimators': [500, 1000],\n",
    "    'subsample' : [1],\n",
    "    'colsample_bytree': [0.5, 1],\n",
    "    'colsample_bylevel': [0.5, 1],\n",
    "    'colsample_bynode': [0.5, 1]\n",
    "}\n",
    "# Create a based model\n",
    "xgb = XGBClassifier(random_state=0)\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = xgb, param_grid = param_grid, \n",
    "                          cv = 5, n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   10.7s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   55.6s\n",
      "[Parallel(n_jobs=-1)]: Done 320 out of 320 | elapsed:  2.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'booster': 'gbtree',\n",
       " 'colsample_bylevel': 0.5,\n",
       " 'colsample_bynode': 1,\n",
       " 'colsample_bytree': 1,\n",
       " 'learning_rate': 0.01,\n",
       " 'max_depth': 2,\n",
       " 'n_estimators': 1000,\n",
       " 'subsample': 1}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Fit the grid search to the training data\n",
    "grid_result = grid_search.fit(X_train, y_train)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.886245 using {'booster': 'gbtree', 'colsample_bylevel': 0.5, 'colsample_bynode': 1, 'colsample_bytree': 1, 'learning_rate': 0.01, 'max_depth': 2, 'n_estimators': 1000, 'subsample': 1}\n"
     ]
    }
   ],
   "source": [
    "## Let's see what our best model parameters are\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "#for mean, stdev, param in zip(means, stds, params):\n",
    " #   print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.89      0.90      0.89       488\n",
      "    Positive       0.88      0.86      0.87       413\n",
      "\n",
      "    accuracy                           0.88       901\n",
      "   macro avg       0.88      0.88      0.88       901\n",
      "weighted avg       0.88      0.88      0.88       901\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Using the best model identified by the grid search, lets re-run the model on the validation set\n",
    "best_grid = grid_search.best_estimator_\n",
    "model = best_grid\n",
    "model.fit(X_train , y_train)\n",
    "y_val_pred = model.predict(X_val)\n",
    "target_names = ['Negative', 'Positive']\n",
    "print(metrics.classification_report(y_val, y_val_pred,target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[438  56]\n",
      " [ 50 357]]\n"
     ]
    }
   ],
   "source": [
    "## Here's what the results of our validation set look like\n",
    "## Results are very similar to our \"default\" classifier tested prior\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_val_pred, y_val)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       1.00      0.90      0.95    933000\n",
      "    Positive       0.01      0.86      0.02      1332\n",
      "\n",
      "    accuracy                           0.90    934332\n",
      "   macro avg       0.51      0.88      0.49    934332\n",
      "weighted avg       1.00      0.90      0.95    934332\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Using the best model identified by the grid search, lets re-run the model on the test set\n",
    "model.fit(X_train , y_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "target_names = ['Negative', 'Positive']\n",
    "print(metrics.classification_report(y_test, y_test_pred,target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[841982    182]\n",
      " [ 91018   1150]]\n"
     ]
    }
   ],
   "source": [
    "## Here's what the results of our test set look like\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test_pred, y_test)\n",
    "print(confusion_matrix)\n",
    "## We can see below that this best-fit model captures a bit more True Positives at the exepnse of a bit more False Positives\n",
    "## Given the imbalance and the relatively higher value of TPs(compared to the penalty of a FP), we will accept this exchange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x5     0.336247\n",
       "x14    0.200221\n",
       "x4     0.130188\n",
       "x7     0.100879\n",
       "x1     0.081846\n",
       "x6     0.035087\n",
       "x11    0.032739\n",
       "x15    0.018671\n",
       "x2     0.018377\n",
       "x3     0.015692\n",
       "x8     0.014360\n",
       "x9     0.010810\n",
       "x12    0.002803\n",
       "x13    0.002081\n",
       "x10    0.000000\n",
       "dtype: float32"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Let's take a look at feature importances. Can we remove some features to get a better model?\n",
    "feature_importances = pd.Series(model.feature_importances_, X_train.columns).sort_values(ascending = False)\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Feature Importances')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Quick plot of features and their importances\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "sns.barplot(y=feature_importances.index, x=feature_importances.values)\n",
    "plt.title('Feature Importances')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x5', 'x14', 'x4', 'x7', 'x1']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Based on the above, let's try setting the cutoff threshold at 0.04 and remove the rest\n",
    "threshold = 0.04\n",
    "imp_feats = list(feature_importances[feature_importances>threshold].keys())\n",
    "imp_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                        colsample_bylevel=0.5,\n",
       "                                        colsample_bynode=1, colsample_bytree=1,\n",
       "                                        gamma=0, learning_rate=0.01,\n",
       "                                        max_delta_step=0, max_depth=2,\n",
       "                                        min_child_weight=1, missing=None,\n",
       "                                        n_estimators=1000, n_jobs=1,\n",
       "                                        nthread=None,\n",
       "                                        objective='binary:logistic',\n",
       "                                        random_state=0, reg_alpha=0,\n",
       "                                        reg_lambda=1, scale_pos_weight=1,\n",
       "                                        seed=None, silent=None, subsample=1,\n",
       "                                        verbosity=1),\n",
       "                max_features=None, norm_order=1, prefit=False, threshold=0.04)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Only pick features that have an importance of more than the threshold 0.04\n",
    "sfm = SelectFromModel(model, threshold)\n",
    "\n",
    "# Train the selector\n",
    "sfm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the data to create a new dataset containing only the most important features\n",
    "# Note: We have to apply the transform to both the training X and test X data.\n",
    "X_important_train = sfm.transform(X_train)\n",
    "X_important_test = sfm.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       1.00      0.89      0.94    933000\n",
      "    Positive       0.01      0.87      0.02      1332\n",
      "\n",
      "    accuracy                           0.89    934332\n",
      "   macro avg       0.51      0.88      0.48    934332\n",
      "weighted avg       1.00      0.89      0.94    934332\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a new random forest classifier for the most important features\n",
    "model_important = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bynode=1, colsample_bytree=0.5, gamma=0,\n",
    "       learning_rate=0.01, max_delta_step=0, max_depth=5,\n",
    "       min_child_weight=1, missing=None, n_estimators=500, n_jobs=1,\n",
    "       nthread=None, objective='binary:logistic', random_state=0,\n",
    "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "       silent=True, subsample=1)\n",
    "\n",
    "# Train the new classifier on the new dataset containing the most important features\n",
    "model_important.fit(X_important_train, y_train)\n",
    "y_pred = model_important.predict(X_important_test)\n",
    "target_names = ['Negative', 'Positive']\n",
    "print(metrics.classification_report(y_test, y_pred,target_names=target_names))\n",
    "\n",
    "# There doesn't appear to be much of a difference compared to our previous model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[834492    179]\n",
      " [ 98508   1153]]\n"
     ]
    }
   ],
   "source": [
    "## Let's look at the confusion matrix for the test set\n",
    "y_pred = model_important.predict(X_important_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_pred, y_test)\n",
    "print(confusion_matrix)\n",
    "\n",
    "## We'll just use the original best_grid model to look at raw predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's see what our raw predictions look like with our original best grid model\n",
    "raw_preds = model.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.864587748252228"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## % of predictions over 0.5\n",
    "len([pred for pred in raw_preds if pred>=0.5])/float(len(raw_preds))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([54.65209369, 21.55775463,  6.82819383,  3.82037648,  3.27699362,\n",
       "        2.43714226,  2.20531888,  2.19375982,  2.08887205,  0.93949474])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Here is what the distribution of raw predictions look like: long tail, skewed right as expected\n",
    "%matplotlib inline\n",
    "plt.hist(raw_preds, bins = 10, range = (0,1))[0]/len(raw_preds)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_preds</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.028840</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.032535</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.050042</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.719810</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.048723</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   raw_preds  y\n",
       "0   0.028840  0\n",
       "1   0.032535  0\n",
       "2   0.050042  0\n",
       "3   0.719810  0\n",
       "4   0.048723  0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Let's do some data manipulation to see what the histogram above looks like just for positive labels\n",
    "X_test['raw_preds'] = raw_preds\n",
    "X_test['y'] = y_test\n",
    "X_test[['raw_preds', 'y']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.87687688,  3.52852853,  2.62762763,  2.62762763,  3.003003  ,\n",
       "        2.77777778,  3.67867868,  6.60660661, 11.93693694, 61.33633634])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Below is a histogram of positive labels in the test set and their corresponding scores\n",
    "positives = X_test[X_test['y']>0]\n",
    "plt.hist(positives.raw_preds, bins = 10, range = (0,1))[0]/len(positives)*100\n",
    "## 61% of the positives received scores of 0.9 or higher (817/1332, 61.3%)\n",
    "## 73% of the positives received scores of 0.8 or higher (972/1332, 73.3%)\n",
    "## 86% of the positives received scores of 0.5 or higher (1145/1332, 86.0%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's save our xgboost model using the pickle module\n",
    "import pickle\n",
    "pickle.dump(model, open(\"xgb.pickle.dat\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base_score': 0.5,\n",
       " 'booster': 'gbtree',\n",
       " 'colsample_bylevel': 0.5,\n",
       " 'colsample_bynode': 1,\n",
       " 'colsample_bytree': 1,\n",
       " 'gamma': 0,\n",
       " 'learning_rate': 0.01,\n",
       " 'max_delta_step': 0,\n",
       " 'max_depth': 2,\n",
       " 'min_child_weight': 1,\n",
       " 'missing': None,\n",
       " 'n_estimators': 1000,\n",
       " 'n_jobs': 1,\n",
       " 'nthread': None,\n",
       " 'objective': 'binary:logistic',\n",
       " 'random_state': 0,\n",
       " 'reg_alpha': 0,\n",
       " 'reg_lambda': 1,\n",
       " 'scale_pos_weight': 1,\n",
       " 'seed': None,\n",
       " 'silent': None,\n",
       " 'subsample': 1,\n",
       " 'verbosity': 1}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## We can use load the model with the following for future use\n",
    "loaded_model = pickle.load(open(\"xgb.pickle.dat\", \"rb\"))\n",
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
