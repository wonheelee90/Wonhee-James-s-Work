{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from util import entropy, information_gain, partition_classes\n",
    "import numpy as np \n",
    "import ast\n",
    "\n",
    "class DecisionTree(object):\n",
    "    def __init__(self):\n",
    "        # Initializing the tree as an empty dictionary or list, as preferred\n",
    "        #self.tree = []\n",
    "        self.tree = {}\n",
    "        pass\n",
    "\n",
    "    def learn(self, X, y):\n",
    "        # TODO: Train the decision tree (self.tree) using the the sample X and labels y\n",
    "        # You will have to make use of the functions in utils.py to train the tree\n",
    "        \n",
    "        # One possible way of implementing the tree:\n",
    "        #    Each node in self.tree could be in the form of a dictionary:\n",
    "        #       https://docs.python.org/2/library/stdtypes.html#mapping-types-dict\n",
    "        #    For example, a non-leaf node with two children can have a 'left' key and  a \n",
    "        #    'right' key. You can add more keys which might help in classification\n",
    "        #    (eg. split attribute and split value)\n",
    "\n",
    "        def split(X, y):\n",
    "            if len(set(y)) == 1:\n",
    "                return y[0]\n",
    "            i = 0 \n",
    "            abs_max_i = 0\n",
    "            abs_max_IG = 0\n",
    "            abs_max_X_left = []\n",
    "            abs_max_X_right = []\n",
    "            abs_max_y_left = []\n",
    "            abs_max_y_right = []\n",
    "            abs_max_j = 0\n",
    "            while i < len(X[0]):\n",
    "                j = 0\n",
    "                current_H = entropy(y)\n",
    "                max_j = 0\n",
    "                max_IG = 0\n",
    "                max_X_left = []\n",
    "                max_X_right = []\n",
    "                max_y_left = []\n",
    "                max_y_right = []\n",
    "                while j < len(y):           \n",
    "                    X_left, X_right, y_left, y_right = partition_classes(X, y, i, X[j][i])\n",
    "                    if information_gain(y, [y_left, y_right]) > max_IG:\n",
    "                        max_IG = information_gain(y, [y_left, y_right])\n",
    "                        max_j = j\n",
    "                        max_X_left = X_left\n",
    "                        max_X_right = X_right\n",
    "                        max_y_left = y_left\n",
    "                        max_y_right = y_right\n",
    "                    j += 1\n",
    "                if max_IG > abs_max_IG:\n",
    "                    abs_max_IG = max_IG\n",
    "                    abs_max_i = i\n",
    "                    abs_max_X_left = max_X_left\n",
    "                    abs_max_X_right = max_X_right\n",
    "                    abs_max_y_left = max_y_left\n",
    "                    abs_max_y_right = max_y_right\n",
    "                    abs_max_j = max_j\n",
    "                i += 1\n",
    "            return {'X_left': abs_max_X_left, 'X_right': abs_max_X_right, 'y_left': abs_max_y_left, 'y_right': abs_max_y_right, 'split_attr': abs_max_i, 'split_val': X[abs_max_j][abs_max_i]}\n",
    "\n",
    "        def recursive_split(X, y):\n",
    "            current_dict = split(X,y)\n",
    "            if (current_dict != 0) and (current_dict != 1):\n",
    "                current_dict['X_left'] = recursive_split(current_dict['X_left'], current_dict['y_left'])\n",
    "            if (current_dict != 0) and (current_dict != 1):\n",
    "                current_dict['X_right'] = recursive_split(current_dict['X_right'], current_dict['y_right'])\n",
    "            return current_dict\n",
    "\n",
    "        self.tree = recursive_split(X,y)\n",
    "        pass\n",
    "\n",
    "\n",
    "    def classify(self, record):\n",
    "        # TODO: classify the record using self.tree and return the predicted label\n",
    "        dict = self.tree\n",
    "        def route(dict, record):\n",
    "            if dict == 0 or dict == 1:\n",
    "                return dict\n",
    "            if type(record[dict['split_attr']]) == int:\n",
    "                if record[dict['split_attr']] <= dict['split_val']:\n",
    "                    return route(dict['X_left'], record)\n",
    "                else:\n",
    "                    return route(dict['X_right'], record)\n",
    "            else:\n",
    "                if record[dict['split_attr']] == dict['split_val']:\n",
    "                    return route(dict['X_left'], record)\n",
    "                else:\n",
    "                    return route(dict['X_right'], record)\n",
    "\n",
    "        #def predict(self, record):\n",
    "        #    predictions = []\n",
    "         #   for i in record:\n",
    "          #      predictions.append(route(dict, i))\n",
    "           # return predictions\n",
    "\n",
    "        return route(dict, record)\n",
    "    \n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from decision_tree import DecisionTree\n",
    "import csv\n",
    "import numpy as np  # http://www.numpy.org\n",
    "import ast\n",
    "\n",
    "# This starter code does not run. You will have to add your changes and\n",
    "# turn in code that runs properly. \n",
    "\n",
    "\"\"\"\n",
    "Here, \n",
    "1. X is assumed to be a matrix with n rows and d columns where n is the\n",
    "number of total records and d is the number of features of each record. \n",
    "2. y is assumed to be a vector of labels of length n.\n",
    "3. XX is similar to X, except that XX also contains the data label for each\n",
    "record.\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "This skeleton is provided to help you implement the assignment.You must \n",
    "implement the existing functions as necessary. You may add new functions\n",
    "as long as they are called from within the given classes. \n",
    "\n",
    "VERY IMPORTANT!\n",
    "Do NOT change the signature of the given functions.\n",
    "Do NOT change any part of the main function APART from the forest_size parameter.  \n",
    "\"\"\"\n",
    "\n",
    "class RandomForest(object):\n",
    "    num_trees = 0\n",
    "    decision_trees = []\n",
    "\n",
    "    # the bootstrapping datasets for trees\n",
    "    # bootstraps_datasets is a list of lists, where each list in bootstraps_datasets is a bootstrapped dataset.\n",
    "    bootstraps_datasets = []\n",
    "\n",
    "    # the true class labels, corresponding to records in the bootstrapping datasets\n",
    "    # bootstraps_labels is a list of lists, where the 'i'th list contains the labels corresponding to records in \n",
    "    # the 'i'th bootstrapped dataset.\n",
    "    bootstraps_labels = []\n",
    "\n",
    "    def __init__(self, num_trees):\n",
    "        # Initialization done here\n",
    "        self.num_trees = num_trees\n",
    "        self.decision_trees = [DecisionTree() for i in range(num_trees)]\n",
    "\n",
    "\n",
    "    def _bootstrapping(self, XX, n):\n",
    "        # Reference: https://en.wikipedia.org/wiki/Bootstrapping_(statistics)\n",
    "        #\n",
    "        # TODO: Create a sample dataset of size n by sampling with replacement\n",
    "        #       from the original dataset XX.\n",
    "        # Note that you would also need to record the corresponding class labels\n",
    "        # for the sampled records for training purposes.\n",
    "\n",
    "        samples = [] # sampled dataset\n",
    "        labels = []  # class labels for the sampled records\n",
    "\n",
    "        r = np.random.randint(n, size = n)\n",
    "        for i in r:\n",
    "            rec = XX[i]\n",
    "            samples.append(rec[0:len(rec)-1])\n",
    "            labels.append(rec[len(rec)-1])\n",
    "        \n",
    "        return (samples, labels)\n",
    "\n",
    "\n",
    "    def bootstrapping(self, XX):\n",
    "        # Initializing the bootstap datasets for each tree\n",
    "        for i in range(self.num_trees):\n",
    "            data_sample, data_label = self._bootstrapping(XX, len(XX))\n",
    "            self.bootstraps_datasets.append(data_sample)\n",
    "            self.bootstraps_labels.append(data_label)\n",
    "\n",
    "\n",
    "    def fitting(self):\n",
    "        # TODO: Train `num_trees` decision trees using the bootstraps datasets\n",
    "        # and labels by calling the learn function from your DecisionTree class.\n",
    "        for DTree, dataset, label in zip(self.decision_trees, self.bootstraps_datasets, self.bootstraps_labels):\n",
    "            DTree.learn(dataset, label)\n",
    "        pass      \n",
    "\n",
    "\n",
    "    def voting(self, X):\n",
    "        y = []\n",
    "\n",
    "        for record in X:\n",
    "            # Following steps have been performed here:\n",
    "            #   1. Find the set of trees that consider the record as an \n",
    "            #      out-of-bag sample.\n",
    "            #   2. Predict the label using each of the above found trees.\n",
    "            #   3. Use majority vote to find the final label for this recod.\n",
    "            votes = []\n",
    "            for i in range(len(self.bootstraps_datasets)):\n",
    "                dataset = self.bootstraps_datasets[i]\n",
    "                if record not in dataset:\n",
    "                    OOB_tree = self.decision_trees[i]\n",
    "                    effective_vote = OOB_tree.classify(record)\n",
    "                    votes.append(effective_vote)\n",
    "\n",
    "            counts = np.bincount(votes)\n",
    "            \n",
    "            if len(counts) == 0:\n",
    "                # TODO: Special case \n",
    "                #  Handle the case where the record is not an out-of-bag sample\n",
    "                #  for any of the trees. \n",
    "                y = np.append(y, self.decision_trees[0].classify(record))\n",
    "\n",
    "                pass\n",
    "            else:\n",
    "                y = np.append(y, np.argmax(counts))\n",
    "\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading hw4-data\n"
     ]
    }
   ],
   "source": [
    "X = list()\n",
    "y = list()\n",
    "XX = list()  # Contains data features and data labels\n",
    "numerical_cols = set([1, 2, 7, 10, 13, 14, 15]) # indices of numeric attributes (columns)\n",
    "\n",
    "# Loading data set\n",
    "print 'reading hw4-data'\n",
    "with open(\"hw4-data.csv\") as f:\n",
    "    next(f, None)\n",
    "\n",
    "    for line in csv.reader(f, delimiter=\",\"):\n",
    "        xline = []\n",
    "        for i in range(len(line)):\n",
    "            if i in numerical_cols:\n",
    "                xline.append(ast.literal_eval(line[i]))\n",
    "            else:\n",
    "                xline.append(line[i])\n",
    "\n",
    "        X.append(xline[:-1])\n",
    "        y.append(xline[-1])\n",
    "        XX.append(xline[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating the bootstrap datasets\n",
      "fitting the forest\n",
      "accuracy: 0.8469\n",
      "OOB estimate: 0.1531\n"
     ]
    }
   ],
   "source": [
    "    # TODO: Initialize according to your implementation\n",
    "    # VERY IMPORTANT: Minimum forest_size should be 10\n",
    "    forest_size = 10\n",
    "    \n",
    "    # Initializing a random forest.\n",
    "    randomForest = RandomForest(forest_size)\n",
    "\n",
    "    # Creating the bootstrapping datasets\n",
    "    print 'creating the bootstrap datasets'\n",
    "    randomForest.bootstrapping(XX)\n",
    "\n",
    "    # Building trees in the forest\n",
    "    print 'fitting the forest'\n",
    "    randomForest.fitting()\n",
    "\n",
    "    # Calculating an unbiased error estimation of the random forest\n",
    "    # based on out-of-bag (OOB) error estimate.\n",
    "    y_predicted = randomForest.voting(X)\n",
    "\n",
    "    # Comparing predicted and true labels\n",
    "    results = [prediction == truth for prediction, truth in zip(y_predicted, y)]\n",
    "\n",
    "    # Accuracy\n",
    "    accuracy = float(results.count(True)) / float(len(results))\n",
    "\n",
    "    print \"accuracy: %.4f\" % accuracy\n",
    "    print \"OOB estimate: %.4f\" % (1-accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
